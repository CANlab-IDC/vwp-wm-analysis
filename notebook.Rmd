---
title: "Gal Matan Analysis - 2018"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. Execute a chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*. When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).


Install (if necessary) and then load the [*VWPre*](https://cran.r-project.org/web/packages/VWPre/index.html) library.
After, set your working directory, this should be the directory with your `<script_name>.R` scripts.
```{r libs_setup, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, include=FALSE}
if(sum(is(try(find.package("knitr"), silent = T)) == "try-error")) install.packages("knitr", "rmarkdown")
library("knitr")

if(sum(is(try(find.package("tidyverse"), silent = T)) == "try-error")) install.packages("tidyverse")
library("tidyverse")

if(sum(is(try(find.package("zoo"), silent = T)) == "try-error")) install.packages("zoo")
library("zoo")

if(sum(is(try(find.package("devtools"), silent = T)) == "try-error")) install.packages("devtools")
#library("devtools")
# 
# if(sum(is(try(find.package("ggTimeSeries"), silent = T)) == "try-error")) devtools::install_github('Ather-Energy/ggTimeSeries')
# library("ggTimeSeries")

if(sum(is(try(find.package("hrbrthemes"), silent = T)) == "try-error")) install.packages("hrbrthemes")

if(sum(is(try(find.package("viridis"), silent = T)) == "try-error")) install.packages("viridis")
if(sum(is(try(find.package("ggedit"), silent = T)) == "try-error")) install.packages("ggedit")
library("ggedit")
if(sum(is(try(find.package("gridExtra"), silent = T)) == "try-error")) install.packages("gridExtra")
library("gridExtra")
#if(sum(is(try(find.package("ggalt"), silent = T)) == "try-error")) install.packages("ggalt")
if(sum(is(try(find.package("ggalt"), silent = T)) == "try-error")) devtools::install_github('Ather-Energy/ggTimeSeries')
library("ggalt")

if(sum(is(try(find.package("padr"), silent = T)) == "try-error")) install.packages("padr")
library("padr")

if(sum(is(try(find.package("lambda.r"), silent = T)) == "try-error")) install.packages("lambda.r")
library("lambda.r")

if(sum(is(try(find.package("VWPre"), silent = T)) == "try-error")) install.packages("VWPre")
library("VWPre")

if(sum(is(try(find.package("lme4"), silent = T)) == "try-error")) install.packages("lme4")
library("lme4")

# replace the string below with your desired working directory
setwd("~/dev/CANlab-IDC/gal-matan-analysis/")

source("./functions.R", local = T, echo = F)
```



Next, load the Sample Report file you exported from the eyelink data viewer. (This may take a couple minutes if the file is large.)
```{r}
# replace the string below with the path to your desired data file
VWdat <- read.table("rawdata/Sample_report_21_6_18_critl_period.txt", header = T, sep = "\t", na.strings = c(".", "NA"), fileEncoding = "ISO-8859-1", encoding = "UTF-8")
```


Run `prep_data` and remove the extra columns.

```{r}
dat0 <- prep_data(data = VWdat, Subject = "RECORDING_SESSION_LABEL", Item = "conditionxnoise")
# if there are columns you want to keep, pass a char list to `rm_extra_DVcols#Keep` (e.g. `Keep = c("RIGHT_PUPIL_SIZE", "LEFT_PUPIL_SIZE")`)
dat0 <- rm_extra_DVcols(dat0, Keep = NULL)
```

Convert the IA id columns to integers
```{r}
dat0$LEFT_INTEREST_AREA_ID <- as.integer(as.character(dat0$LEFT_INTEREST_AREA_ID))
dat0$RIGHT_INTEREST_AREA_ID <- as.integer(as.character(dat0$RIGHT_INTEREST_AREA_ID))
```

If needed, recode the interest areas. If you are using the standard CANlab experiment for the Eyelink, you don't need to modify this input. After recoding the IAs run `check_ia` above again.
```{r}
dat0 <- recode_ia(data=dat0, IDs=c("0"="0", "1"="1", "2"="2", "3"="3",
                                     "4"="4", "5"="0", "6"="0", "7"="0","8"="0", "9"="0"), 
                    Labels=c(Bottom="Outside",Center="Outside",Distractor="Distractor", Filler_1="Filler_1",Filler_2="Filler_2",Left="Outside",       
                             Right="Outside",Target="Target",Top="Outside"))
```

Next relabel the `NA`s and add a time column. The `Time` parameter of `create_time_series` is for the amount of time before the word onset that the critical period starts, (normally `200`).
```{r}
dat1 <- relabel_na(data = dat0, NoIA = 5)
dat2 <- create_time_series(data = dat1, Adjust = 200)
```

```{r}
check_time_series(data = dat2)
check_msg_time(data = dat2, Msg = "WITHOUT_HA")
check_eye_recording(data = dat2)
dat3 <- select_recorded_eye(data = dat2, Recording = "LandR", WhenLandR = "Right")
```

Clear unneeded environment variables
```{r}
remove(VWdat, dat0, dat1, dat2)
```

Load wm cap information & merge with dat3
```{r}
# digit_span <- read.csv("rawdata/Digit incorrect_Exp1.csv", header=T, col.names=c("TRIAL_ID"))
wmcaps <- read.csv("rawdata/WM_span.csv", header=T, col.names=c("Subject", "wmcap"), colClasses = c("factor", "factor"));

dat3$Subject <- as.factor(sub("111t", "111", as.character(dat3$Subject)));

dat3 <- merge(x = dat3, y = wmcaps, by = "Subject", all = T);
levels(dat3$wmcap) <- c("low", "high");

dat3 <- addTrialId(dat3)
```

gather trial stats & merge into dat4
```{r}
dat4 <- merge(
  x = dat3,
  y = dat3 %>% collect_trial_stats %>% select(Subject, TRIAL_INDEX, TrialLength, TrialSampleLength, Selection.Time, Touch.Time),
  by = c("Subject", "TRIAL_INDEX"),
  all = T
  )
```



Pad the trials
```{r}
start_val <- -200
end_val <- 3500
dat4_pad <- dat4 %>%
  arrange(as.numeric(as.character(Subject)), as.numeric(TRIAL_INDEX), as.numeric(Time)) %>%
  trim_to_selection %>%
  pad_trials(start_val = start_val, end_val = end_val, .fill_type = "Target")
# dat4_pad_locf <- dat4 %>%
#   arrange(as.numeric(Subject), as.numeric(TRIAL_INDEX), as.numeric(Time)) %>%
#   trim_to_selection %>%
#   pad_trials(start_val = start_val, end_val = end_val, .fill_type = "LOCF")
```

check padding & filling
```{r}
#dat4_pad %>% group_vars()
dat4_pad %>%
  #filter(Subject == 100) %>%
  group_by(Subject, TRIAL_INDEX) %>%
  summarize(
    nsamples = n(),
    length = last(Time),
    first_idx = first(SAMPLE_INDEX),
    last_idx = last(SAMPLE_INDEX),
    last_fix = last(IA_ID),
    Selection.Time = last(Selection.Time),
    Touch.Time = last(Touch.Time)
  ) %>%
  ungroup %>%
  arrange(as.numeric(Subject), as.numeric(TRIAL_INDEX));
dat4_pad %>%
  filter(Time >=1800) %>%
  #addExcludeColumns %>%
  #exclude_practice %>%
  #exclude_inc_sel %>%
  #exclude_inc_dig %>%
  #exclude_kbd_sel %>%
  #exclude_bad_sub %>%
  group_by(Time) %>%
  summarize(ns = n()) %>%
  filter(ns != 1)
  
```

Bin the stuff
```{r}
check_samplingrate(dat4_pad);
# ds_options(SamplingRate = 500);

dat5 <- bin_prop(dat4_pad, NoIA = 4, BinSize = 20, SamplingRate = 500)
check_samplingrate(dat5);
check_samples_per_bin(dat5);

```

clear unnecessary data
```{r}
remove(dat3, dat4, dat4_pad, dat4_pad_locf, binned_temp)
```

Prep for (g)lmer
```{r}
# dat4_ot <- dat4;
# dat4_ot$TimeBin <- ((dat4$Time + 200) / 200) + 1;
# 
# t <- poly((unique(dat4_ot$TimeBin)), 3);
# dat4_ot[,paste("ot", 1:3, sep="")] <- t[dat4_ot$TimeBin, 1:3];

dat5_for_lmer <- dat5 %>%
  exclude_all %>%
  mutate(Time = Time / 1000) %>%
  select(condition, wmcap, load, Subject, Time, starts_with("IA"))
```

Model design:
```{}
IA_1_P ~ (ot1+ot2+ot3)*condition
  + (ot1+ot2+ot3)*load*wmcap
  + (1+ot1+ot2+ot3 | Subject)
  + (1+ot1 | Subject:condition)
  + (1+ot1 | Subject:load)
```

select & rescale
```{r}
restricted_targfix_dat <- (
  keepcritcorrect(dat4_pad, IncludeFiller = FALSE) %>%
    select(., condition, wmcap, load, ot1, ot2, ot3, Subject, Time, starts_with("IA"))
);

scaled_targfix_dat <- (
  restricted_targfix_pad %>%
    mutate(.,
        ot1 = scale(ot1, center = TRUE, scale = max(ot1, rm.na=TRUE)/100), 
        ot2 = scale(ot2, center = TRUE, scale = max(ot2, rm.na=TRUE)/100), 
        ot3 = scale(ot3, center = TRUE, scale = max(ot3, rm.na=TRUE)/100)
    ) %>%
    select(., condition, wmcap, load, ot1, ot2, ot3, Subject, Time, starts_with("IA"))
);
#summary(scaled_targfix_dat)
```

```{r}
dat5 %>% mutate(Time = Time / 1000) %>% mutate(Time2 = Time^2, Time3 = Time^3) %>% mutate(Time2 = Time^2, Time3 = Time^3) %>% select(IA_1_P, Time, Time2, Time3, condition, load, wmcap, Subject) %>% summary
```



Run lmer 
```{r}
# targetfix_m.reml.3 <- lmer(IA_1_P ~ (ot1+ot2+ot3)*condition
#   + (ot1+ot2+ot3)*load*wmcap
#   + (1+ot1+ot2+ot3 | Subject)
#   + (1+ot1 | Subject:condition)
#   + (1+ot1 | Subject:load),
#   control = lmerControl(optimizer="bobyqa"),
#   data=scaled_targfix_dat,
#   REML=T)
# targetfix_m.nm.3 <- lmer(IA_1_P ~ (ot1+ot2+ot3)*condition
#   + (ot1+ot2+ot3)*load*wmcap
#   + (1+ot1+ot2+ot3 | Subject)
#   + (1+ot1+ot2+ot3 | Subject/condition:load),
#   verbose=1,
#   control = lmerControl(optimizer="Nelder_Mead", optCtrl =list(maxfun=25000)),
#   data=scaled_targfix_dat,
#   REML=T)
targetfix_m.full <- lmer(IA_1_P ~ (Time + I(Time^2) + I(Time^3))*condition
  + (Time + I(Time^2) + I(Time^3))*load*wmcap
  + (1+Time + I(Time^2) + I(Time^3) | Subject/condition:load),
  verbose=2,
  # control = lmerControl(optimizer="bobyqa"),
  control = lmerControl(optimizer="Nelder_Mead", optCtrl =list(maxfun=25000)),
  data= dat5_for_lmer, # %>% select(condition, wmcap, load, Subject, Time, starts_with("IA")) %>% scale_dat,
  REML=T)
```

plot lmer 
```{r}
scaled_targfix_dat$mfit <- fitted(targetfix_m.nm.3);
ggplot(scaled_targfix_dat, aes(Time, IA_1_P, color=wmcap)) + facet_wrap(~ load + condition) +
  theme_minimal() + 
  stat_summary(fun.y=mean, geom="point") +
  stat_summary(aes(y=mfit), fun.y=mean, geom="line") +
  labs(y="Fixation Proportion", x="Time since word onset (ms)") + 
  scale_color_manual(values=c("red", "blue"))
```


```{r}
dat4_pad %>%
  exclude_all %>%
  #filter(Subject == "122" & condition == "r") %>%
  #filter(Time <= 3000) %>%
  #pad_int("Time", -200, 3000, step=2, group="TRIAL_INDEX") %>%
  group_by(Subject) %>%
  #fill_by_function(fun=last) %>%
  
  ggplot(aes(Time)) +
    theme_bw() +
    facet_grid(IA_ID~condition) +
    #geom_freqpoly() +
    stat_bin(geom = "bar", position = "stack", binwidth = 50) +
    scale_color_brewer(type = "qual", palette = 2, guide = "legend") +
    xlim(-200, 3000);

dat4_pad %>%
  exclude_all %>%
  bin_prop(NoIA = 4, BinSize = 20, SamplingRate = 500) %>%
  ggplot(aes(Time, IA_1_P)) +
    geom_horizon(bandwidth = 0.1) +
    facet_grid(Subject~condition) +
    viridis::scale_fill_viridis(name = "Fixations on target", discrete=TRUE, labels=scales::percent(seq(0, 1, 0.1)+0.1)) +
    xlim(-200, 3000);
#stat_steamgraph()
dat4_pad %>%
  exclude_all %>%
  #group_by(Subject) %>%
  #filter(Subject == "122" & condition == "r")
  group_by(factor(IA_ID))
  ggplot(aes(Time, fill=factor(IA_ID))) +
  theme_bw() +
  facet_wrap(~TRIAL_INDEX) +
  #geom_dotplot(method="histodot") +
  stat_bin(geom = "bar", position = "stack", binwidth = 50) +
  scale_fill_brewer(type = "qual", palette = 2, guide = "legend") +
  xlim(0, 3000)
```

```{r}
binned_temp <- dat4_pad %>% 
  addExcludeColumns %>%
  exclude_practice %>%
  exclude_inc_sel %>%
  exclude_inc_dig %>%
  exclude_kbd_sel %>%
  exclude_bad_sub %>%
  bin_prop(NoIA = 4, BinSize = 20, SamplingRate = 500)

binned_temp %>%
  group_by(Subject, TRIAL_INDEX) %>%
  filter(NSamples != 10) %>%
  select(Event, Time, Subject, TRIAL_INDEX, starts_with("IA"), NSamples, condition)
  #summarize(ns = n())
```


Export padded, binned data for McMurray analysis
```{r}
# dat4_pad %>% 
#   addExcludeColumns %>%
#   exclude_practice %>%
#   exclude_inc_sel %>%
#   exclude_inc_dig %>%
#   exclude_kbd_sel %>%
#   exclude_bad_sub %>%
#   bin_prop(NoIA = 4, BinSize = 20, SamplingRate = 500) %>%
dat5 %>% 
  addExcludeColumns %>%
  exclude_practice %>%
  exclude_inc_sel %>%
  exclude_inc_dig %>%
  exclude_kbd_sel %>%
  exclude_bad_sub %>%
  # Select just the columns you want
  select(
    Subject,
    Item,
    starts_with("IA"),
    Event,
    # TRIAL_INDEX,
    condition,
    # target,
    # distractor,
    # filler_1,
    # filler_2,
    wmcap,
    load,
    critical,
    Time
  ) %>%
  group_by(Subject, critical, condition, Time, load, wmcap) %>%
  summarize(
    Avg_Target = mean(IA_1_P),
    Avg_Distractor_1 = mean(IA_2_P),
    Avg_Competitor = mean(IA_3_P),
    Avg_Distractor_2 = mean(IA_4_P)
  ) %>%
  ungroup %>%
  # group_by(Subject, critical, condition, load, wmcap) %>%
  # arrange(Time) %T>%
  # ungroup %>%
  arrange(Subject, critical, condition, load, wmcap, Time) %>%
  mutate(wmcap_L1_H2 = as.numeric(wmcap), condition_F1_C2_R3 = as.numeric(condition), critical_N1_Y2 = as.numeric(critical))
  write.csv(file="./mcmurray-data/Averaged-mcmurray-data.csv", row.names = FALSE)
  # Order the data by Subject, Trial, and Time
  #arrange(Subject, Time) %T>%
  #(
  #  . %>%
  #    select(-IA_1_P, everything()) %>%
  #    write.csv(file="./mcmurray-data/target-correct-padded-target-data.csv")
  #) %>%
  #(
  #  . %>%
  #    select(-IA_3_P, everything()) %>%
  #    write.csv(file="./mcmurray-data/competitor-correct-padded-target-data.csv")
  #)
```




```{r}
dat4_pad_locf %>% 
  addExcludeColumns %>%
  exclude_practice %>%
  exclude_inc_sel %>%
  exclude_inc_dig %>%
  exclude_kbd_sel %>%
  exclude_bad_sub %>%
  bin_prop(NoIA = 4, BinSize = 20, SamplingRate = 500) %>%
  # Select just the columns you want
  select(
    Subject,
    Item,
    starts_with("IA"),
    Event,
    TRIAL_INDEX, 
    condition,
    target,
    distractor,
    filler_1,
    filler_2,
    load,
    critical,
    Time
  ) %>%
  # Order the data by Subject, Trial, and Time
  arrange(Subject, TRIAL_INDEX, Time) %T>%
  (
    . %>%
      select(-IA_1_P, everything()) %>%
      write.csv(file="./mcmurray-data/target-correct-padded-locf-data.csv")
  ) %>%
  (
    . %>%
      select(-IA_3_P, everything()) %>%
      write.csv(file="./mcmurray-data/competitor-correct-padded-locf-data.csv")
  )
```
